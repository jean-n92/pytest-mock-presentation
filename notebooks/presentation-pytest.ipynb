{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79bdcda8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Make your life easier by using unittest.**mock**\n",
    "\n",
    "### Also, a small introduction to mocking, APIs and cats ðŸˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba5d496",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a mock?\n",
    "### Is it the same as a *stub*? Or as a *dummy*? Or as a *fake*?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276a33a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![SO](http://localhost:5500/lib/img3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb0052",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### A mock is an *interaction-based* object whose purpose is to *override* other objects and return user-defined values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694c2e60",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Its main implementation in Python is via the builtin package `unittest.mock`. [Official documentation](https://docs.python.org/3/library/unittest.mock.html) says that\n",
    ">`unittest.mock` is a library for testing in Python. It allows you to replace parts of your system under test with mock objects and make assertions about how they have been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015094bd",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Hidden imports go here\n",
    "import sys\n",
    "import ipytest\n",
    "import requests\n",
    "import pyspark\n",
    "import unittest\n",
    "import time\n",
    "from unittest import mock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d131935",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's start with the *very* basics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25acb97",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def a_random_function(arg1: str, arg2: str) -> str:\n",
    "    return arg2 + arg1\n",
    "\n",
    "a_random_function(\"AMRO\", \"ABN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2189b5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now let's now make things slightly less linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b72cb3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def another_function(arg1: int, arg2: int, arg3: str, arg4: str) -> str:\n",
    "    return a_random_function(arg3, arg4) + str((arg1 + arg2)//2)\n",
    "\n",
    "another_function(2, 4, \"Ê˜=)âˆ«\", \"(=Ê˜á†½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6975a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How is this related to unit testing?    \n",
    "Let's take the definition of *unit testing*. According to Wikipedia (the main source of information for our century), we can define unit testing as:\n",
    ">\"A software testing method by which individual units of source code â€” sets of one or more computer program modules together with associated control data, usage procedures, and operating procedures â€” are tested to determine whether they are fit for use.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086b5e0a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The dilemma is:\n",
    "> \" How can we test something over which we have no control? \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58a3b7d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In our specific case, let's take `a_random_function(arg1, arg2)` as given.    \n",
    "Let's say we import it from some other package, that doesn't belong to us.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac295b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We run into this issue many times: the most common use case is when we interact with the filesystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5711c3af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's redefine our `another_function()` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4021c59e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def another_function(arg1: str, arg2: str) -> str:\n",
    "    return a_random_function(sys.argv[0], sys.argv[1]) + \" - \" + str((arg1 + arg2)//2)\n",
    "\n",
    "another_function(10, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fa17e4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As you can see, I have no possible control over `sys.argv`: they get defined at runtime, once I run my application.    \n",
    "How can we account for them, or get *some* degree of control?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2742e5c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Fortunately, `unittest.mock` allows us to perform this task in a relatively relaxed way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d4a57",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@mock.patch(\"sys.argv\", [\"One\", \"Two\"])\n",
    "def another_function(arg1: int, arg2: int) -> str:\n",
    "    return a_random_function(sys.argv[0], sys.argv[1]) + \" - \" + str((arg1 + arg2)//2)\n",
    "\n",
    "another_function(10, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d2875",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(sys.argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7219a8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![cat](http://localhost:5500/lib/img1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d267346",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Test-related imports go here\n",
    "\n",
    "ipytest.autoconfig()\n",
    "test_args = [\"--showlocals\", \n",
    "            \"-x\", \n",
    "            \"--cov-report\", \n",
    "            \"term-missing\",\n",
    "            \"--cov\",\n",
    "            \"neon.utils.functions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cc4fab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's get to our cats ðŸˆ\n",
    "Since I really love cats, I'd like to know more about them.    \n",
    "Fortunately, someone created the **completely free** [Cat facts API](https://catfact.ninja/) which can return nice (and interesting) facts about our feline friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc8b5fe",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "requests.get(url=\"https://catfact.ninja/fact\").json()[\"fact\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54bc296",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the purpose of this presentation, I made a **whole application** to collect facts about cats. The application does two main things:\n",
    "- Collects a certain number of facts by querying the API\n",
    "- Saves everything as a nice table into my local HIVE metastore\n",
    "\n",
    "I called the application **Neon** (just because that's the first name I got from a random generator).    \n",
    "The application code and its tests are freely available on my Github profile (link at the end of the presentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6f4535",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's start making use of it then!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6dfb83",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from neon.utils.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052ee0c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![outline](http://localhost:5500/lib/img4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20dc39a",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "interesting_facts = process_data(usernumber=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef8d82",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Each API call generates a JSONs.    \n",
    "`process_data()` conveniently packs them into a list, over which we can easily iterate: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62dca1",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for entry in interesting_facts:\n",
    "    print(entry[\"fact\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4996da",
   "metadata": {},
   "source": [
    "Let's now store these important facts inside my table, so then they don't get lost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ec593",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "spark = establish_spark()\n",
    "group_and_save(spark, facts=interesting_facts)\n",
    "df = spark.read.table(\"default.random_cats_facts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f63d7c",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.show(100,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20004f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As you can see, the whole procedure is **very slow**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e24244",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is due to a random `waiting` variable that I added in order to simulate a slow connection, a very inefficient backend on the server side, or anything that can get in between."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70142a81",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since the `waiting` variable polls a random amount of seconds between 1 and 10, we're talking here about an *average* waiting time of *5 seconds per request*.\n",
    "In case you don't believe me, check the [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) for statistical reference ðŸ¤“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3fa8ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What can I do to make the whole thing more efficient, while testing for the main functionality?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c773f30a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are two main issues over here:\n",
    "1) **I don't wanna wait 5 seconds for each call to the API**, but I'd like to be sure that the call works nonetheless (i.e. no test data, I don't care about the data: I want my functionality to work)    \n",
    "2) **I don't wanna save the data I retrieve every single time**, since I have no control over its saving process. I just know that, as soon as I run the application, the data will be saved somewhere. That's not good for testing purposes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5525d7f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's use our mocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de104e72",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class TestAPI(unittest.TestCase):\n",
    "    @mock.patch(\"neon.utils.functions.fake_request\", return_value=None)\n",
    "    def test_retrieve_data_without_waiting(self, patched_request):\n",
    "        t0 = time.perf_counter()\n",
    "        actual: dict = retrieve_data(waiting=5)\n",
    "        actual_keys: list = [key for key in actual]\n",
    "        expected_keys: list = [\"fact\", \"length\"]\n",
    "        t1 = time.perf_counter() - t0\n",
    "        self.assertEqual(actual_keys, expected_keys)\n",
    "        self.assertLess(t1, 10)\n",
    "    \n",
    "    @mock.patch(\"neon.utils.functions.retrieve_data\", return_value={\"fact\" : \"This is a random fact\", \"length\" : \"-99\"})\n",
    "    def test_process_data_with_custom_load(self, patched_retrieve):\n",
    "        t0 = time.perf_counter()\n",
    "        actual: list = process_data(usernumber=5, waiting=5)\n",
    "        expected: list = [{\"fact\" : \"This is a random fact\", \"length\" : \"-99\"}]*5\n",
    "        t1 = time.perf_counter() - t0\n",
    "        self.assertEqual(actual, expected)\n",
    "        self.assertLess(t1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c0a3f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "first_test_suite = TestAPI()\n",
    "ipytest.run(*test_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0f6a20",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And now to the Spark part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e1a37",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class TestSparkFunctions(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls) -> None:\n",
    "        cls.mocked_data: List[dict] = [{\"fact\": \"This is a random fact\", \"length\": \"-99\"}]\n",
    "\n",
    "    @mock.patch(\"pyspark.sql.readwriter.DataFrameWriter.saveAsTable\")\n",
    "    def test_group_and_save_with_patching(self, patched_writer):\n",
    "        patched_writer.new = True\n",
    "        spark: SparkSession = establish_spark()\n",
    "        data: List[dict] = self.mocked_data\n",
    "        group_and_save(spark, data)\n",
    "        patched_writer.assert_called()\n",
    "\n",
    "    @mock.patch(\"neon.utils.functions.fake_request\", return_value=None)\n",
    "    def test_group_and_save_with_api_load(self, patched_request):\n",
    "        mocked_save = mock.create_autospec(group_and_save)\n",
    "        spark: SparkSession = establish_spark()\n",
    "        data: list[dict] = process_data(usernumber=5, waiting=2)\n",
    "        expected: bool = mocked_save(spark, data)\n",
    "        mocked_save.assert_called()\n",
    "        self.assertTrue(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d101329",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "second_test_suite = TestSparkFunctions()\n",
    "ipytest.run(*test_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d2ed97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem solved!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cf1e71",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![cat](http://localhost:5500/lib/img2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8183ec",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Useful links:\n",
    "[Catfacts (API reference)](https://catfact.ninja/)    \n",
    "[This application (Git repo)](https://github.com/jean-n92/pytest-mock-presentation)    \n",
    "[Where to patch (Documentation)](https://docs.python.org/3/library/unittest.mock.html#where-to-patch)    \n",
    "[Quick start with mock (Documentation)](https://docs.python.org/3/library/unittest.mock.html#quick-guide)    \n",
    "[Difference between mock and stub (StackOverflow)](https://stackoverflow.com/questions/3459287/whats-the-difference-between-a-mock-stub)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "4a7b606e264437b67c76b6a90ca9c891af4f0d4e775e00cab262968ebd59eaa3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
